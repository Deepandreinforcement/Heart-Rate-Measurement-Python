{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "525d72bb",
   "metadata": {},
   "source": [
    "Gerekli kütüphaneleri yüklüyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38b9f808",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.signal import butter, filtfilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45d7cbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "# Burada kullanacağımız modeli seçiyoruz. Bu model ile yüz tespiti yapacağız\n",
    "model= YOLO(\"yolov8n-face.pt\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8730ba",
   "metadata": {},
   "source": [
    "Bandpass filtre tanımlıyoruz. Bu filtre ile belirli değerler arasındaki sinyalleri alıyoruz. Bu değer aralığının dışındaki sıfır yapıyor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8c97880",
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_bandpass_filter(data, fs, lowcut, highcut, order=1):\n",
    "    \n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    y = filtfilt(b, a, data, axis=0)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3583f3f3",
   "metadata": {},
   "source": [
    "Kodda kullanacağımız önemli fonksiyonlardan bir tanesi. Burada ilk önce resmi levels sayısı kadar boyut olarak yarıda birine düşürüyoruz. Örneğin levels=3 olursa 3 sefer yarıda bire düşürme işlemi uygularız. Böylece görüntü hem genişlik hem de yükseklik olarak 1/8 boyutuna ulaşacak. Ardından levels sayısı kadar resmi 2 katına çıkarıyoruz. Böylece resim orijinal boyutuna ulaşmış olacak. Fakat arada bir kayıp olacak. Bu kaybı alpha katsayısı ile çarpıp orijinal resme ekliyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "429116b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def amplify_spatial_laplacian_pyramid(frame, levels=3, alpha=50):\n",
    "    \n",
    "    pyramid = frame.copy()\n",
    "    for _ in range(levels):\n",
    "        pyramid = cv2.pyrDown(pyramid)\n",
    "    for _ in range(levels):\n",
    "        pyramid = cv2.pyrUp(pyramid)\n",
    "    laplacian = frame - pyramid\n",
    "    amplified_frame = frame + alpha * laplacian\n",
    "    return amplified_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd5b8fe",
   "metadata": {},
   "source": [
    "Burada amaç tahmini olarak kalp atış hızını belirlemek. Fakat burada birçok bağlı değişken var. Bundan dolayı videodan videoya bu değerlerin kalibre edilmesi gerekebilir. Ayrıca buradaki sonuçları direk bir fiziksel cihaza bağlayıp ölçmediğim için sonuçların %100 doğru olduğunu söyleyemem. Fakat yaptığım hesaplar sonucunda bu video için buradaki değerlerin yüksek doğrulukla sonuç verdiklerini buldum. siz kendi videonuz için buradaki değerleri değiştirebilirsiniz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddd0eff",
   "metadata": {},
   "source": [
    "Kodun çalışma mantığı ise şöyle. İnsan yüzünde çok küçük renk değişimleri olur. Bunlar gözle görülmesi çok zor. Burada bu değişimleri yakalayıp bunları büyütüp ardından bunların ortalamasını alıp bir sinyal oluşturyoruz.Bu sinyalde zirveyi temsil eden noktalar genelde nabzın attığı yeri ifade diyor. Yani renk değişiminin en fazla olduğu noktalarda nabız atışı oluyor diyebiliriz. Ardından bu noktaları kullanarak frekanstan kalp atış hızını hesaplama yapıyoruz. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc60d04",
   "metadata": {},
   "source": [
    "Burada ilk önce belirli sayıda frame birikmesi gerekiyor. Ardından bunları işleme sokup nabzı tahmin ediyoruz. Ben bu tahmin işleminde kullanılacak frame sayısını 150 olarak belirledim. 150. frame'den sonra hesaplama başlıyor. Sonraki tahmin işlemini ise anında değil 30 frame sonra yapsın diye belirledim. Yani her 30 frame'de bir tahmin işlemi yaplıyor. Bu da kabaca 1 saniyeye denk geliyor. Ayrıca burada sadece yeşil kanalı kullandım. Mavi ve kırmızı renkteki kanalı kullanmadım. Okuduğum makalelerde sadece yeşil rengin kullanılmasının  daha iyi sonuçlar verdiği söyleniyordu. Siz isterseniz diğer renkleri de kullanabilirsiniz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedfe8c8",
   "metadata": {},
   "source": [
    "Buradaki kod videoda tek kişinin olduğu videolar için ayarlanmıştır. Videoda birden fazla kişi varsa tracking işlemi uygulanıp buradaki adaımlar her bir yüz için tekrarlanmalı"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66813987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Videoyu yüklüyoruz\n",
    "cap= cv2.VideoCapture('video.mp4')\n",
    "\n",
    "# Bu kodu yorumdan çıkarırsanız bilgisayarın kamerası kullanılır.\n",
    "#cap= cv2.VideoCapture(0)\n",
    "\n",
    "# Videonun FPS'sini alıyoruz.\n",
    "frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "#Yazı fontunu ayarlıyoruz.\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "# Kalp atışı hızı\n",
    "heart_rate=0\n",
    "\n",
    "# Renk değşimlerinin ortalamasını bu listeye ekliyoruz.\n",
    "mean_values = []\n",
    "\n",
    "# Her 30 Frame'de bir tahmin yapıyoruz. Bunu kontrol etmek için kullanacağımız değişken\n",
    "buffer_count=0\n",
    "\n",
    "\n",
    "while True:\n",
    "    # Görüntüyü alıyoruz videodan\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Bu değişkeni her frame'de bir arttıryoruz.\n",
    "    buffer_count+=1\n",
    "  \n",
    "    # Kameradan görüntü gelmezse döngğden çıkar.\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Resmi RGB uzayına çeviriyoruz.\n",
    "    imgs=cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Resme blur uyguluyoruz, gürültüyü azaltmak için\n",
    "    imgs = cv2.GaussianBlur(imgs, (5, 5), 0)\n",
    "    \n",
    "    # Resmi yüz tespiti yapabilen modele resmi verdik.\n",
    "    results = model(imgs,verbose=False) \n",
    "    \n",
    "    # Modelin tespit edebildiği sınıflar. Buradaki sonuç sadace insan yüzü.\n",
    "    labels=results[0].names\n",
    "    \n",
    "    # Her bir nesne yani yüz için bir for döngüsü çalışacak. Burada yüzün koordinatlarını buluyoruz.\n",
    "    for i in range(len(results[0].boxes)):\n",
    "        x1,y1,x2,y2=results[0].boxes.xyxy[i]\n",
    "        score=results[0].boxes.conf[i]\n",
    "        label=results[0].boxes.cls[i]\n",
    "        x1,y1,x2,y2,score,label=int(x1),int(y1),int(x2),int(y2),float(score),int(label)\n",
    "        \n",
    "        # Yüzü mavi bir dikdörtgen içine alıyoruz.\n",
    "        cv2.rectangle(frame,(x1,y1),(x2,y2),(255,0,0),10)\n",
    "        \n",
    "        \n",
    "        # Burada yüzün olduğu olduğu kısmı görselden kırpacağız. Görseli 3 kere 2'de bir oranı küçültüp büyüteceğimiz \n",
    "        # Yani 8 kat olduğu için resmin hem genişliği hem de hem de yüksekliği 8' tam bölünebilmeli. \n",
    "        # Diğer türlü resim boyutu uyumsuz olacağı için hata verecek küçülüp büyürken\n",
    "        # O yüzden iki uç noktadan çıkarıp genişlik ve yükseliklik tanımlarken bu değerlerden 8'e bölününce kalan \n",
    "        # değerleri de çıakrıyoruz.\n",
    "        h=y2-y1-((y2-y1)%8)\n",
    "        w=x2-x1-((x2-x1)%8)\n",
    "        \n",
    "        # Görseli yüz kısmından kesitk. İsterseniz sadece alın bölgesini de kullanabilirsiniz.\n",
    "        roi_color = frame[y1:y1+h, x1:x1+w]\n",
    "        \n",
    "        # Yüzü amplify fonksiyonuna veriyoruz.\n",
    "        roi_color = amplify_spatial_laplacian_pyramid(roi_color, levels=3, alpha=200)\n",
    "        \n",
    "        # Resmin yeşil kanalını alıyoruz.\n",
    "        green_channel = roi_color[:, :, 1]\n",
    "        \n",
    "        # Burada ortalama alıyoruz.\n",
    "        mean_val = np.mean(green_channel)\n",
    "        \n",
    "        #Bunu da bu listeye ekliyoruz. Bu her bir frame için yapılıyor. Yani bu listedeki her bir değer\n",
    "        # her bir frame'nin yeşil kanalındaki değişimin ortalaması\n",
    "        mean_values.append(mean_val)\n",
    "        \n",
    "        # burada fonksiyondan gelen görüntüyü ekranda gösteriyoruz.\n",
    "        cv2.imshow(\"roicolor\",roi_color)\n",
    "        # Sadece tek bir yüz alsın diye koddan çıkıyoruz.\n",
    "        break\n",
    "    \n",
    "    # Eğer biriken ortalama sayısı 150 olmuşsan ve son tahmin işleminden itibaren 30 frame geçmişse tahmin kısmına geçiyoruz.\n",
    "    \n",
    "    if len(mean_values)>149 and buffer_count>29:\n",
    "        \n",
    "        # Bu değişkeni her tahmin işleminde sıfırlıyoruz.\n",
    "        buffer_count=0 \n",
    "        \n",
    "        # Numpy array'e çeviriyoruz\n",
    "        mean_values_array = np.array(mean_values)\n",
    "        \n",
    "        # Her seferinde 150 değere baktığımız için ilk 30 değeri birikme olmasın diye siliyoruz\n",
    "        del mean_values[:30]\n",
    "        \n",
    "        # Sinyale bandpass filtre uyfuluyoruz. Buradaki 0.8 48 nabzı 2 ise 120 nabzı temsil ediyor. \n",
    "        # Bu değerleri tahmini en düşük ve en yüksek nabız değerleri\n",
    "        filtered_signal = temporal_bandpass_filter(mean_values_array, frame_rate, lowcut=0.8, highcut=2)\n",
    "        \n",
    "        # Burada zirveleri buluyoruz. Buradaki 2.0 değeri zirveler arasındaki fark için ayarladığımız bir\n",
    "        # Bu koddaki en önemli parametre. O yüzden bunu değiştirirken dikkatli değiştirin. Yoksa çok uçuk\n",
    "        # değerler bulabilirsiniz.\n",
    "        peaks, _ = find_peaks(filtered_signal, distance=frame_rate/2.0)\n",
    "        \n",
    "        # Zirve sayısı birden büyükse kod çalışacak\n",
    "        if len(peaks) > 1:\n",
    "            \n",
    "            # burada zirveler arasındaki farkı bulup FPS'e bölüyoruz.\n",
    "            intervals = np.diff(peaks) / frame_rate\n",
    "            \n",
    "            # Ardından bunların ortalamasını alıp 60'a bölüyoruz. \n",
    "            # Çünkü kalp atış hızı olan BPM dakikadaki kalp atış hızını söyler\n",
    "            heart_rate = 60 / np.mean(intervals)\n",
    "            \n",
    "    # Kalp atış hızı hesaplanmışsa 0'dan büyüktür. Diğer türlü default olan 0'dır\n",
    "    if heart_rate>0:\n",
    "        \n",
    "        # Burada ekranda iyi gözüksün diye sol üst köşeyi mor renk yapıyoruz.\n",
    "        frame[0:100,0:400]=(102,0,153)\n",
    "        \n",
    "        # Ekranın  sol üst köşesine kalp atış hızını yazdırıyoruz.\n",
    "        text='BPM:'+str(int(heart_rate))\n",
    "        cv2.putText(frame, text,(30, 80), font, 3, (255,255,255), 3)\n",
    "    \n",
    "    cv2.imshow(\"kamera\",frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a332c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
